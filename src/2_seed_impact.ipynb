{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **The Impact of Random Seeds on Training**\n",
    "***Authors: Bram Silue, Prof. dr. Pieter Libin, Prof. dr. Niel Hens.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How to Run**\n",
    "Please open and run this notebook in Colab:\n",
    "\n",
    "[![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/plibin/vala-rl-25/blob/main/src/2_seed_impact.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction**\n",
    "In this notebook, we investigate the impact of the random seed on the training of a machine learning model. More specifically, we will investigate the impact on the DQN model implemented in `1_dqn.ipynb`.\n",
    "\n",
    "First, we import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we plot multiple learning curves. For your convenience, we have already generated 10 different learning curves on the Lunar Lander problem with 10 different seeds using the code from `1_dqn.ipynb`. \n",
    "\n",
    "We define a plotting function below. Note that to make the resulting plot easier to interpret, the curves are smoothed using  Savitzky-Golay filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_learning_curves(base_url: str = 'https://raw.githubusercontent.com/plibin/vala-rl-25/main/src/learning_curves',\n",
    "                             file_name_pattern: str = 'learning_curve__seed={}.csv',\n",
    "                             window_length: int = 25,\n",
    "                             polyorder: int = 3,\n",
    "                             seeds: int = 10) -> None:\n",
    "    \"\"\"\n",
    "    Plots smoothed learning curves from multiple files using the Savitzky-Golay filter.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    base_url          :  The base URL where the CSV files are hosted.\n",
    "    file_name_pattern :  The pattern for the file names, \n",
    "                         with '{}' as the placeholder for the seed number.\n",
    "    window_length     :  The length of the filter window.\n",
    "    polyorder         :  The order of the polynomial used to fit the samples.\n",
    "    seeds             :  The number of seeds being considered.\n",
    "\n",
    "    \"\"\"\n",
    "    # Create a new figure for the summary plot.\n",
    "    plt.figure()\n",
    "\n",
    "    # Loop over the files and add each learning curve to the summary plot.\n",
    "    for seed in range(seeds):\n",
    "        # Construct the full URL for the file.\n",
    "        file_url = f\"{base_url}/{file_name_pattern.format(seed)}\"\n",
    "        \n",
    "        # Load the learning curve data from the URL.\n",
    "        cumulative_rewards = []\n",
    "        try:\n",
    "            response = requests.get(file_url)\n",
    "            response.raise_for_status()  # produce an error for bad responses.\n",
    "            \n",
    "            # Parse the CSV content from the URL response.\n",
    "            reader = csv.DictReader(response.text.splitlines())\n",
    "            for row in reader:\n",
    "                cumulative_rewards.append(float(row['Cumulative Reward']))\n",
    "        \n",
    "        # Raise an error for bad responses.\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data from {file_url}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Convert the reward list to a tensor.\n",
    "        rewards_t = torch.tensor(cumulative_rewards, dtype=torch.float)\n",
    "        \n",
    "        # Apply Savitzky-Golay filter to smooth the data.\n",
    "        if len(rewards_t) >= window_length:\n",
    "            smoothed_rewards = savgol_filter(rewards_t.numpy(), \n",
    "                                             window_length=window_length, \n",
    "                                             polyorder=polyorder)\n",
    "            # Plot smoothed cumulative rewards.\n",
    "            plt.plot(smoothed_rewards, label=f'Seed {seed}', linewidth=2)\n",
    "\n",
    "    # Configure plot labels and legend.\n",
    "    plt.xlabel('Episode', fontweight='bold')\n",
    "    plt.ylabel('Cumulative Reward', fontweight='bold')\n",
    "    plt.title('Summary of Smoothed DQN Learning Curves', fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now generate the plot of all of these learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_learning_curves()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is apparent from the plot above that the random seed significantly impacts the model's performance during training. Therefore, a single training run on a single seed is not a good representation of a model's performance and stability.\n",
    "\n",
    "A good way to visualize model performance is by plotting the mean and standard deviation of multiple runs across different seeds. The number of runs to execute depends on how thorough we want to be and on the computational burden we can afford. In this example, we limit ourselves to just 10 runs. We define a plotting function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves_summary(base_url: str = \"https://raw.githubusercontent.com/plibin/vala-rl-25/main/src/learning_curves\",\n",
    "                                 file_name_pattern: str = 'learning_curve__seed={}.csv',\n",
    "                                 window_length: int = 15,\n",
    "                                 polyorder: int = 3) -> None:\n",
    "    \"\"\"\n",
    "    Plots the mean and standard deviation of smoothed learning curves from multiple files using the Savitzky-Golay filter.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    base_url          :  The base URL where the CSV files are hosted.\n",
    "    file_name_pattern :  The pattern for the file names, \n",
    "                         with '{}' as the placeholder for the seed number.\n",
    "    window_length     :  The length of the filter window.\n",
    "    polyorder         :  The order of the polynomial used to fit the samples.\n",
    "\n",
    "    \"\"\"\n",
    "    # List to store all cumulative rewards arrays.\n",
    "    all_cumulative_rewards = []\n",
    "\n",
    "    # Loop over the 10 files and read the learning curves.\n",
    "    for seed in range(10):\n",
    "        # Construct the full URL for the file.\n",
    "        file_url = f\"{base_url}/{file_name_pattern.format(seed)}\"\n",
    "        \n",
    "        # Load the learning curve data from the URL.\n",
    "        cumulative_rewards = []\n",
    "        try:\n",
    "            response = requests.get(file_url)\n",
    "            response.raise_for_status()  # produce an error for bad responses.\n",
    "            \n",
    "            # Parse the CSV content from the URL response.\n",
    "            reader = csv.DictReader(response.text.splitlines())\n",
    "            for row in reader:\n",
    "                cumulative_rewards.append(float(row['Cumulative Reward']))\n",
    "\n",
    "        # Raise an error for bad responses.   \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data from {file_url}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Append the cumulative rewards to the list.\n",
    "        all_cumulative_rewards.append(cumulative_rewards)\n",
    "\n",
    "    # Check if any data was successfully loaded.\n",
    "    if not all_cumulative_rewards:\n",
    "        print(\"No valid data loaded. Check the file URLs or data format.\")\n",
    "        return\n",
    "\n",
    "    # Convert the list of cumulative rewards to a numpy array for easier manipulation.\n",
    "    all_cumulative_rewards = np.array(all_cumulative_rewards)\n",
    "\n",
    "    # Calculate the mean and standard deviation across seeds.\n",
    "    mean_rewards = np.mean(all_cumulative_rewards, axis=0)\n",
    "    std_rewards = np.std(all_cumulative_rewards, axis=0)\n",
    "\n",
    "    # Apply Savitzky-Golay filter to smooth the mean rewards.\n",
    "    if len(mean_rewards) >= window_length:\n",
    "        smoothed_mean_rewards = savgol_filter(mean_rewards, window_length=window_length, polyorder=polyorder)\n",
    "\n",
    "    # Create a new figure for the summary plot.\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot the smoothed mean cumulative rewards.\n",
    "    plt.plot(smoothed_mean_rewards, label='Mean Cumulative Reward', linewidth=2, color='blue')\n",
    "\n",
    "    # Plot the standard deviation as a shaded area.\n",
    "    plt.fill_between(range(len(smoothed_mean_rewards)), \n",
    "                     smoothed_mean_rewards - std_rewards, \n",
    "                     smoothed_mean_rewards + std_rewards, \n",
    "                     color='green', alpha=0.3, label='Standard Deviation')\n",
    "\n",
    "    # Configure plot labels and legend.\n",
    "    plt.xlabel('Episode', fontweight='bold')\n",
    "    plt.ylabel('Cumulative Reward', fontweight='bold')\n",
    "    plt.title('Mean and Standard Deviation of DQN Learning Curves', fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now generate this summary plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
